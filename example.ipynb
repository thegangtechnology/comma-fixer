{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the module to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comma-fixer in ./.venv/lib/python3.13/site-packages (1.0.8)\n",
      "Requirement already satisfied: build<2.0.0,>=1.3.0 in ./.venv/lib/python3.13/site-packages (from comma-fixer) (1.3.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.6 in ./.venv/lib/python3.13/site-packages (from comma-fixer) (3.1.6)\n",
      "Requirement already satisfied: networkx<4.0,>=3.5 in ./.venv/lib/python3.13/site-packages (from comma-fixer) (3.5)\n",
      "Requirement already satisfied: numpy<3.0.0,>=2.3.2 in ./.venv/lib/python3.13/site-packages (from comma-fixer) (2.3.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.3.2 in ./.venv/lib/python3.13/site-packages (from comma-fixer) (2.3.2)\n",
      "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.13/site-packages (from build<2.0.0,>=1.3.0->comma-fixer) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.13/site-packages (from build<2.0.0,>=1.3.0->comma-fixer) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2<4.0.0,>=3.1.6->comma-fixer) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas<3.0.0,>=2.3.2->comma-fixer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas<3.0.0,>=2.3.2->comma-fixer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas<3.0.0,>=2.3.2->comma-fixer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.3.2->comma-fixer) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install comma-fixer --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comma_fixer.column import Column\n",
    "from comma_fixer.fixer import Fixer, create_chunks\n",
    "from comma_fixer.schema import Schema\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Schema\n",
    "\n",
    "To create a Schema, we have to define all the columns with the column name and type, with additional arguments on whether the columns are nullable.\n",
    "\n",
    "Each column will have a function to determine whether a given token can be placed within that column. \n",
    "\n",
    "For `datetime` columns, it is critical that the input is in the ISO 8601 datetime format, i.e. `%Y-%m-%d` or `YYYY-MM-DD`, as this is the format accepted \n",
    "by the `pandas` library used for storing the dataset before exporting to CSV.\n",
    "\n",
    "For example, assume we have the entry string \"1,Bob,Johnson,twenty three,False,\", and are checking whether \"twenty three\" is suitable for the \"age\" column.\n",
    "Since the \"age\" column only accepts numeric values, it will return False. However, if the entry string were \"1,Bob,Johnson,23,False,\", the column's verifier \n",
    "would return True for \"23\".\n",
    "\n",
    "Other types of columns can be created as well, but a `pd.Series` object must be supplied to be able to create a `pd.DataFrame` when exporting to CSV. This requires \n",
    "importing `pandas`. All arguments must be given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_1 = Schema.new(columns=[\n",
    "    Column.numeric(name=\"id\"),\n",
    "    Column.string(name=\"firstname\", is_nullable=False, has_commas=False, has_spaces=False),\n",
    "    Column.string(name=\"lastname\", is_nullable=False, has_commas=False, has_spaces=False),\n",
    "    Column.numeric(name=\"age\"),\n",
    "    Column.new(name=\"cat_owner\", data_type=bool, series_type=pd.Series(dtype=bool), is_nullable=False, has_commas=False, has_spaces=False, format=None),\n",
    "    Column.string(name=\"cat_names\", is_nullable=True, has_commas=True, has_spaces=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a Schema, its contents can be displayed in a table format. However, newer columns can not be added into existing Schemas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_07d2a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_07d2a_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_07d2a_level0_col1\" class=\"col_heading level0 col1\" >type</th>\n",
       "      <th id=\"T_07d2a_level0_col2\" class=\"col_heading level0 col2\" >nullable</th>\n",
       "      <th id=\"T_07d2a_level0_col3\" class=\"col_heading level0 col3\" >has commas</th>\n",
       "      <th id=\"T_07d2a_level0_col4\" class=\"col_heading level0 col4\" >has spaces</th>\n",
       "      <th id=\"T_07d2a_level0_col5\" class=\"col_heading level0 col5\" >format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_07d2a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_07d2a_row0_col0\" class=\"data row0 col0\" >id</td>\n",
       "      <td id=\"T_07d2a_row0_col1\" class=\"data row0 col1\" >int</td>\n",
       "      <td id=\"T_07d2a_row0_col2\" class=\"data row0 col2\" >False</td>\n",
       "      <td id=\"T_07d2a_row0_col3\" class=\"data row0 col3\" >False</td>\n",
       "      <td id=\"T_07d2a_row0_col4\" class=\"data row0 col4\" >False</td>\n",
       "      <td id=\"T_07d2a_row0_col5\" class=\"data row0 col5\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07d2a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_07d2a_row1_col0\" class=\"data row1 col0\" >firstname</td>\n",
       "      <td id=\"T_07d2a_row1_col1\" class=\"data row1 col1\" >str</td>\n",
       "      <td id=\"T_07d2a_row1_col2\" class=\"data row1 col2\" >False</td>\n",
       "      <td id=\"T_07d2a_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "      <td id=\"T_07d2a_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "      <td id=\"T_07d2a_row1_col5\" class=\"data row1 col5\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07d2a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_07d2a_row2_col0\" class=\"data row2 col0\" >lastname</td>\n",
       "      <td id=\"T_07d2a_row2_col1\" class=\"data row2 col1\" >str</td>\n",
       "      <td id=\"T_07d2a_row2_col2\" class=\"data row2 col2\" >False</td>\n",
       "      <td id=\"T_07d2a_row2_col3\" class=\"data row2 col3\" >False</td>\n",
       "      <td id=\"T_07d2a_row2_col4\" class=\"data row2 col4\" >False</td>\n",
       "      <td id=\"T_07d2a_row2_col5\" class=\"data row2 col5\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07d2a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_07d2a_row3_col0\" class=\"data row3 col0\" >age</td>\n",
       "      <td id=\"T_07d2a_row3_col1\" class=\"data row3 col1\" >int</td>\n",
       "      <td id=\"T_07d2a_row3_col2\" class=\"data row3 col2\" >False</td>\n",
       "      <td id=\"T_07d2a_row3_col3\" class=\"data row3 col3\" >False</td>\n",
       "      <td id=\"T_07d2a_row3_col4\" class=\"data row3 col4\" >False</td>\n",
       "      <td id=\"T_07d2a_row3_col5\" class=\"data row3 col5\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07d2a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_07d2a_row4_col0\" class=\"data row4 col0\" >cat_owner</td>\n",
       "      <td id=\"T_07d2a_row4_col1\" class=\"data row4 col1\" >bool</td>\n",
       "      <td id=\"T_07d2a_row4_col2\" class=\"data row4 col2\" >False</td>\n",
       "      <td id=\"T_07d2a_row4_col3\" class=\"data row4 col3\" >False</td>\n",
       "      <td id=\"T_07d2a_row4_col4\" class=\"data row4 col4\" >False</td>\n",
       "      <td id=\"T_07d2a_row4_col5\" class=\"data row4 col5\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07d2a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_07d2a_row5_col0\" class=\"data row5 col0\" >cat_names</td>\n",
       "      <td id=\"T_07d2a_row5_col1\" class=\"data row5 col1\" >str</td>\n",
       "      <td id=\"T_07d2a_row5_col2\" class=\"data row5 col2\" >True</td>\n",
       "      <td id=\"T_07d2a_row5_col3\" class=\"data row5 col3\" >True</td>\n",
       "      <td id=\"T_07d2a_row5_col4\" class=\"data row5 col4\" >True</td>\n",
       "      <td id=\"T_07d2a_row5_col5\" class=\"data row5 col5\" >None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10e1c4ad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixer\n",
    "\n",
    "After creating a Schema, it can be used to create a `Fixer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer_1 = Fixer.new(schema_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file can be processed one at a time by passing in the filepath to the fixer. This will create a `Parsed` object where the processed, valid rows can be exported into a CSV file, and invalid rows can be viewed.\n",
    "\n",
    "Primarily, invalid rows may occur if there are multiple ways of parsing the row to fit the schema, or there is no valid parsing. This may be a result of a weak, non-restrictive schema. To fix this, the schema should contain further restrictive elements such as RegEx formatting.\n",
    "\n",
    "If enabled in `fix_file`, invalid rows can also print out their possible tokenisations for fixing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "The `example_1.csv` file only has one column with commas, so there should not be any invalid rows aside from rows which are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,firstname,lastname,age,cat_owner,cat_names\n",
      "1,John,Appleseed,43,True,Apple\n",
      "2,John,Wick,35,False,\n",
      "3,Bob,Smiles,25,True,Fluffy,Fluffy Sr.\n",
      "4,Jennifer,Law,26,True,Snowy\n",
      "5,Taylor,Fast,35,True,Grey,Benson,Button\n",
      "6,Tom,Jack,18,True,,Mimi\n",
      "7,Jake,Howler,30,True,,,Mob,Psycho\n",
      "8,Pujan,,Sir,32,True,,,\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Fixer Logs:No paths found at line index 8.\n",
      "WARNING:Fixer Logs:No paths found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 9            \n",
      " Number of invalid entries: 1\n"
     ]
    }
   ],
   "source": [
    "parsed_example_1 = fixer_1.fix_file(file=\"./examples/example_1.csv\", skip_first_line=True, show_possible_parses=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing in a filepath, the default encoding is \"utf-8\", however, if the file to be processed has a different encoding, it can be passed in as an argument.\n",
    "\n",
    "For example, for files in Thai encoding:\n",
    "- `.fix_file(file=\"/path/to/csv/file.csv\", encoding=\"Cp874\")` \n",
    "- `.fix_file(file=\"../examples/example_1.csv\", encoding=\"TIS-620\")`\n",
    "\n",
    "`TextIOWrapper` types can also be passed into the `fix_file` function if the user would like to open the file themselves, as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Fixer Logs:No paths found at line index 8.\n",
      "WARNING:Fixer Logs:No paths found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 9            \n",
      " Number of invalid entries: 1\n"
     ]
    }
   ],
   "source": [
    "file_buffer = open(\"./examples/example_1.csv\", \"r\", encoding=\"Cp874\")\n",
    "parsed_example_1 = fixer_1.fix_file(file=file_buffer, skip_first_line=True, show_possible_parses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7 entries, 0 to 6\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         7 non-null      object\n",
      " 1   firstname  7 non-null      object\n",
      " 2   lastname   7 non-null      object\n",
      " 3   age        7 non-null      object\n",
      " 4   cat_owner  7 non-null      object\n",
      " 5   cat_names  7 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 392.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "parsed_example_1.export_to_csv_best_effort(filepath=\"./examples/example_1_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,firstname,lastname,age,cat_owner,cat_names\n",
      "1,John,Appleseed,43,True,Apple\n",
      "2,John,Wick,35,False,\n",
      "3,Bob,Smiles,25,True,\"Fluffy,Fluffy Sr.\"\n",
      "4,Jennifer,Law,26,True,Snowy\n",
      "5,Taylor,Fast,35,True,\"Grey,Benson,Button\"\n",
      "6,Tom,Jack,18,True,Mimi\n",
      "7,Jake,Howler,30,True,\"Mob,Psycho\"\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_1_parsed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed, valid entries can also be returned as a `pandas.DataFrame` object for further manipulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7 entries, 0 to 6\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         7 non-null      object\n",
      " 1   firstname  7 non-null      object\n",
      " 2   lastname   7 non-null      object\n",
      " 3   age        7 non-null      object\n",
      " 4   cat_owner  7 non-null      object\n",
      " 5   cat_names  7 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 392.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>age</th>\n",
       "      <th>cat_owner</th>\n",
       "      <th>cat_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>Appleseed</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>John</td>\n",
       "      <td>Wick</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Smiles</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>Fluffy,Fluffy Sr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Law</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>Fast</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>Grey,Benson,Button</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Tom</td>\n",
       "      <td>Jack</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>Mimi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Jake</td>\n",
       "      <td>Howler</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>Mob,Psycho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id firstname   lastname age cat_owner           cat_names\n",
       "0  1      John  Appleseed  43      True               Apple\n",
       "1  2      John       Wick  35     False                    \n",
       "2  3       Bob     Smiles  25      True   Fluffy,Fluffy Sr.\n",
       "3  4  Jennifer        Law  26      True               Snowy\n",
       "4  5    Taylor       Fast  35      True  Grey,Benson,Button\n",
       "5  6       Tom       Jack  18      True                Mimi\n",
       "6  7      Jake     Howler  30      True          Mob,Psycho"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example_1.convert_to_dataframe_best_effort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that only 7 out of 8 entries are in the parsed CSV, meaning that only 8 rows were valid according to the schema created.\n",
    "\n",
    "We can inspect the invalid entries by printing them out,viewing as a dataframe (if there are many invalid entries) or by exporting to CSV file, similarly to how we would export the valid entries.\n",
    "\n",
    "For invalid entries, the exported columns will be `line index, invalid entry`, where line index is respective to the original CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\tLine entry\n",
      "8\t8,Pujan,,Sir,32,True,,,\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   line number    1 non-null      int64 \n",
      " 1   invalid entry  1 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "parsed_example_1.print_all_invalid_entries()\n",
    "parsed_example_1.export_invalid_entries_to_csv(filepath=\"./examples/example_1_invalid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line number,invalid entry\n",
      "8,\"8,Pujan,,Sir,32,True,,,\"\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_1_invalid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the only entry that is invalid is on line 8, and this entry is invalid because there is a null entry in a non-null column (lastname)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "However, if there are multiple columns allowing commas consecutively, the fixer will be unable to parse rows as efficiently compared to other schemas, i.e. schemas where columns with commas are separated by a different type, such as numeric types.\n",
    "\n",
    "An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Fixer Logs:Multiple paths found at line index 0 - needs to be resolved.\n",
      "INFO:Fixer Logs:['1', 'chanom', 'chayen,orange,orange']\n",
      "INFO:Fixer Logs:Correct CSV format: 1,chanom,\"chayen,orange,orange\"\n",
      "INFO:Fixer Logs:['1', 'chanom,chayen', 'orange,orange']\n",
      "INFO:Fixer Logs:Correct CSV format: 1,\"chanom,chayen\",\"orange,orange\"\n",
      "INFO:Fixer Logs:['1', 'chanom,chayen,orange', 'orange']\n",
      "INFO:Fixer Logs:Correct CSV format: 1,\"chanom,chayen,orange\",orange\n",
      "WARNING:Fixer Logs:Multiple paths found at line index 1 - needs to be resolved.\n",
      "INFO:Fixer Logs:['2', 'chayen', 'olieang,orange,black']\n",
      "INFO:Fixer Logs:Correct CSV format: 2,chayen,\"olieang,orange,black\"\n",
      "INFO:Fixer Logs:['2', 'chayen,olieang', 'orange,black']\n",
      "INFO:Fixer Logs:Correct CSV format: 2,\"chayen,olieang\",\"orange,black\"\n",
      "INFO:Fixer Logs:['2', 'chayen,olieang,orange', 'black']\n",
      "INFO:Fixer Logs:Correct CSV format: 2,\"chayen,olieang,orange\",black\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 4            \n",
      " Number of invalid entries: 2\n"
     ]
    }
   ],
   "source": [
    "schema_2 = Schema.new(columns=[\n",
    "    Column.numeric(\"id\"),\n",
    "    Column.string(\"cat_names\", is_nullable=False,has_commas=True,has_spaces=True),\n",
    "    Column.string(\"cat_colours\", is_nullable=False,has_commas=True,has_spaces=False)\n",
    "])\n",
    "\n",
    "fixer_2 = Fixer.new(schema_2)\n",
    "\n",
    "parsed_example_2 = fixer_2.fix_file(\"./examples/example_2.csv\", skip_first_line=False, show_possible_parses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\tLine entry\n",
      "0\t1,chanom,chayen,orange,orange\n",
      "1\t2,chayen,olieang,orange,black\n"
     ]
    }
   ],
   "source": [
    "parsed_example_2.print_all_invalid_entries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for lines with multiple commas, the processing fails as it is unable to tell apart which tokens should be placed in which column. However, with `show_possible_parses` enabled, we can see the exact line and its possible parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2 entries, 0 to 1\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           2 non-null      object\n",
      " 1   cat_names    2 non-null      object\n",
      " 2   cat_colours  2 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 64.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "parsed_example_2.export_to_csv_best_effort(\"./examples/example_2_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cat_names,cat_colours\n",
      "3,muffin,orange\n",
      "4,chanom,orange\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_2_parsed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the parsed dataset will only result in valid rows being exported.\n",
    "\n",
    "However, if we had restricted the Schema further given that the contents are known, then we are more likely to achieve better results.\n",
    "\n",
    "It should be noted that this would not perform as well for columns with variable data, i.e. columns containing long text. It should go without saying, unless the contents are from a strict set of items, having incredibly restrictive schemas may also cause poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 4            \n",
      " Number of invalid entries: 0\n"
     ]
    }
   ],
   "source": [
    "schema_2_revised = Schema.new(columns=[\n",
    "    Column.numeric(\"id\"),\n",
    "    Column.string(\"cat_names\", is_nullable=False,has_commas=True,has_spaces=True, format=r\"^(?!orange|black|white|calico|tabby)\"),\n",
    "    Column.string(\"cat_colours\", is_nullable=False,has_commas=True,has_spaces=False, format=r\"^(orange|black|white|calico|tabby)\")\n",
    "])\n",
    "\n",
    "fixer_2_revised = Fixer.new(schema_2_revised)\n",
    "\n",
    "parsed_example_2_revised = fixer_2_revised.fix_file(\"./examples/example_2.csv\", skip_first_line=False, show_possible_parses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           4 non-null      object\n",
      " 1   cat_names    4 non-null      object\n",
      " 2   cat_colours  4 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "parsed_example_2_revised.export_to_csv_best_effort(\"./examples/example_2_parsed_regex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cat_names,cat_colours\n",
      "1,\"chanom,chayen\",\"orange,orange\"\n",
      "2,\"chayen,olieang\",\"orange,black\"\n",
      "3,muffin,orange\n",
      "4,chanom,orange\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_2_parsed_regex.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this example, let us assume that the third column `cat_colours` can only contain the following values: [orange, black, white, calico, tabby].\n",
    "\n",
    "With this, we can create a restrictive schema as seen above. However, we will also have to add this restriction to the column prior, so that the prior column can determine whether it belongs to it or not. Otherwise, there may still be multiple possible parses.\n",
    "\n",
    "For example, `1, \"chanom, chayen, orange\", orange` could be a possible parse if we did not specify `cat_names` to exclude values from `cat_colours`. \n",
    "\n",
    "Hence, it is important to strictly define each column such that there are clear distinctions between consecutive columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 9            \n",
      " Number of invalid entries: 0\n"
     ]
    }
   ],
   "source": [
    "schema_3 = Schema.new(columns=[\n",
    "    Column.numeric(\"id\"),\n",
    "    Column.string(\"username\",is_nullable=False,has_commas=False,has_spaces=False),\n",
    "    Column.numeric(\"number_of_platforms\"),\n",
    "    Column.string(\"platforms\",is_nullable=True,has_commas=True,has_spaces=False),\n",
    "    Column.numeric(\"number_of_cats\"),\n",
    "    Column.string(\"cat_names\",is_nullable=True,has_commas=True,has_spaces=True)\n",
    "])\n",
    "\n",
    "fixer_3 = Fixer.new(schema_3)\n",
    "\n",
    "parsed_example_3 = fixer_3.fix_file(\"./examples/example_3.csv\", skip_first_line=True, show_possible_parses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8 entries, 0 to 7\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   8 non-null      object\n",
      " 1   username             8 non-null      object\n",
      " 2   number_of_platforms  8 non-null      object\n",
      " 3   platforms            8 non-null      object\n",
      " 4   number_of_cats       8 non-null      object\n",
      " 5   cat_names            8 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "parsed_example_3.export_to_csv_best_effort(\"./examples/example_3_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,username,number_of_platforms,platforms,number_of_cats,cat_names\n",
      "1,john_appleseed,2,\"facebook,instagram\",1,Apple\n",
      "2,john_wick,0,,0,\n",
      "3,bob,1,instagram,2,\"fluffy,fluffy sr.\"\n",
      "4,jlaw,1,instagram,1,snowy\n",
      "5,tay_fast,2,\"instagram,youtube\",3,\"grey,benson,button\"\n",
      "6,tommyj,0,,1,mimi\n",
      "7,jakeyh,2,\"twitter,instagram\",2,\"mob,Psycho\"\n",
      "8,pujanf,0,,2,\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_3_parsed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a clear divider between the two comma columns, valid parsings can be produced and exported. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4\n",
    "\n",
    "If the values of a column with commas is known, i.e. the values came from a multiple choice question on a form, they can be specified to help identify whether a value can be placed within a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 6            \n",
      " Number of invalid entries: 0\n",
      "Index\tLine entry\n"
     ]
    }
   ],
   "source": [
    "schema_4 = Schema.new(columns=[\n",
    "    Column.string(\"favourite_cat_colours\", is_nullable=False,has_commas=True,has_spaces=False, format=r\"^(orange|black|tabby|white|calico)\"),\n",
    "    Column.string(\"favourite_colour_reason\", is_nullable=False,has_commas=True,has_spaces=True, format=r\"^(?!orange|black|tabby|white|calico)\")\n",
    "])\n",
    "\n",
    "fixer_4 = Fixer.new(schema_4)\n",
    "\n",
    "parsed_example_4 = fixer_4.fix_file(\"./examples/example_4.csv\", skip_first_line=True, show_possible_parses=True)\n",
    "parsed_example_4.print_all_invalid_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Parsed Logs:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   favourite_cat_colours    5 non-null      object\n",
      " 1   favourite_colour_reason  5 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 120.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "parsed_example_4.export_to_csv_best_effort(filepath=\"./examples/example_4_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "favourite_cat_colours,favourite_colour_reason\n",
      "\"orange,calico\",\"because orange cats are very silly,and calicos are very pretty\"\n",
      "black,because black cats are very sweet despite superstition\n",
      "white,my cat is white so i like white cats (my cat)\n",
      "\"orange,tabby\",I like tabby cats because they look like striped fish.\n",
      "\"orange,calico,black,white,tabby\",\"I like all cat colours,why discriminate?\"\n"
     ]
    }
   ],
   "source": [
    "! cat ./examples/example_4_parsed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By specifying the RegEx formatting of tokens that are expected in each column, it can help with parsing tokens into their respective columns. \n",
    "\n",
    "However, this can only be done for columns where their expected values are known. For text columns, this may not be as effective.\n",
    "\n",
    "As seen in the example above, the last column is a text column and its contents can be random. In this case, we can try to differentiate from the previous column since we know the previous column's values and exclude all tokens which begin with items from the previous column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5 - Processing a file in chunks\n",
    "\n",
    "In the case where the file is being processed is extremely large, i.e. millions of rows, it may benefit to break down the processing into smaller chunks rather than doing it all in one go. \n",
    "\n",
    "To do this, there is a supplied utility function for creating chunks for processing with `fix_file`. This utility function can be used by first importing from the fixer submodule like so:\n",
    "```python\n",
    "from comma_fixer.fixer import create_chunks\n",
    "```\n",
    "\n",
    "Then, supply the filepath or `TextIOBuffer` or `StringIO` objects, the amount of lines/rows per chunk, and whether to skip the first line.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "create_chunks(filepath=\"/path/to/csv/file.csv\", lines_per_chunk=100_000, skip_first_line=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 13\n"
     ]
    }
   ],
   "source": [
    "all_chunks = create_chunks(filepath=\"examples/example_5.csv\", lines_per_chunk=100_000, skip_first_line=True)\n",
    "print(f\"Number of chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of lines per chunk is not specified, or `None` is passed, then the number of chunks created is based on the amount of cores the device has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 11\n",
      "Number of cores on device: 10\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "all_chunks = create_chunks(filepath=\"examples/example_5.csv\", lines_per_chunk=None, skip_first_line=True)\n",
    "print(f\"Number of chunks created: {len(all_chunks)}\")\n",
    "print(f\"Number of cores on device: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create lots of chunks via a low number of lines per chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 60481\n"
     ]
    }
   ],
   "source": [
    "all_chunks = create_chunks(filepath=\"examples/example_5.csv\", lines_per_chunk=20, skip_first_line=True)\n",
    "print(f\"Number of chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object is a list of `StringIO` objects, which will allow for processing with `fix_file` directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "schema_5 = Schema.new(\n",
    "    columns=[\n",
    "        Column.string(f\"col_{i}\", False, False, False) for i in range(1,51)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer_5 = Fixer.new(schema=schema_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Fixer Logs:No paths found at line index 1.\n",
      "WARNING:Fixer Logs:No paths found at line index 2.\n",
      "WARNING:Fixer Logs:No paths found at line index 3.\n",
      "WARNING:Fixer Logs:No paths found at line index 4.\n",
      "WARNING:Fixer Logs:No paths found at line index 5.\n",
      "WARNING:Fixer Logs:No paths found at line index 6.\n",
      "WARNING:Fixer Logs:No paths found at line index 8.\n",
      "WARNING:Fixer Logs:No paths found at line index 11.\n",
      "WARNING:Fixer Logs:No paths found at line index 13.\n",
      "WARNING:Fixer Logs:No paths found at line index 16.\n",
      "WARNING:Fixer Logs:No paths found at line index 18.\n",
      "WARNING:Fixer Logs:No paths found at line index 19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 20            \n",
      " Number of invalid entries: 12\n"
     ]
    }
   ],
   "source": [
    "parsed_example_5_chunk_0 = fixer_5.fix_file(all_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular file, a majority of the rows are malformed. Because of this, the logger will print out warnings when it does not find a possible parsing given the schema to alert the user. Since the number of lines per chunk is extremely large, over 100,000 lines per chunk, this may result in a lot of logs being printed which could negatively impact the runtime. \n",
    "\n",
    "To prevent this, an additional parameter has been added to the `Fixer.fix_file` function to write the logs to a file for later inspection rather than printing. \n",
    "\n",
    "For this example, we will adjust the chunk size to be smaller for easier inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 2420\n"
     ]
    }
   ],
   "source": [
    "small_chunks = create_chunks(filepath=\"examples/example_5.csv\", lines_per_chunk=500, skip_first_line=True)\n",
    "print(f\"Number of chunks created: {len(small_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `log_file` is set to true, a subfolder will be created in the current directory called `logs` and log files will be created with the naming format to `comma_fixer_%Y%m%d_%H%M%S.log`. Currently, there is no way to modify where the logs are written to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 500            \n",
      " Number of invalid entries: 271\n"
     ]
    }
   ],
   "source": [
    "parsed_example_5_chunk_1 = fixer_5.fix_file(small_chunks[1], show_possible_parses=True, log_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us investigate the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:Fixer Logs:No paths found at line index 1.\n",
      "WARNING:Fixer Logs:No paths found\n",
      "WARNING:Fixer Logs:No paths found at line index 3.\n",
      "WARNING:Fixer Logs:No paths found\n",
      "WARNING:Fixer Logs:No paths found at line index 6.\n",
      "WARNING:Fixer Logs:No paths found\n",
      "WARNING:Fixer Logs:No paths found at line index 8.\n",
      "WARNING:Fixer Logs:No paths found\n",
      "WARNING:Fixer Logs:No paths found at line index 9.\n",
      "WARNING:Fixer Logs:No paths found\n"
     ]
    }
   ],
   "source": [
    "! head -n 10 ./logs/comma_fixer_20250918_162426.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are mostly warnings dictating that no valid path has been found in some of the rows, with no possible parses.\n",
    "\n",
    "Note that large matrices may become truncated. \n",
    "\n",
    "Let us try again with an example file from earlier where there are multiple possible parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been processed!\n",
      "Number of total entries: 4            \n",
      " Number of invalid entries: 2\n"
     ]
    }
   ],
   "source": [
    "parsed_example_2_logs = fixer_2.fix_file(\"./examples/example_2.csv\", skip_first_line=False, show_possible_parses=True, log_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:Fixer Logs:Multiple paths found at line index 0 - needs to be resolved.\n",
      "INFO:Fixer Logs:['1', 'chanom', 'chayen,orange,orange']\n",
      "INFO:Fixer Logs:Correct CSV format: 1,chanom,\"chayen,orange,orange\"\n",
      "INFO:Fixer Logs:['1', 'chanom,chayen', 'orange,orange']\n",
      "INFO:Fixer Logs:Correct CSV format: 1,\"chanom,chayen\",\"orange,orange\"\n",
      "INFO:Fixer Logs:['1', 'chanom,chayen,orange', 'orange']\n",
      "INFO:Fixer Logs:Correct CSV format: 1,\"chanom,chayen,orange\",orange\n",
      "WARNING:Fixer Logs:Multiple paths found at line index 1 - needs to be resolved.\n",
      "INFO:Fixer Logs:['2', 'chayen', 'olieang,orange,black']\n",
      "INFO:Fixer Logs:Correct CSV format: 2,chayen,\"olieang,orange,black\"\n",
      "INFO:Fixer Logs:['2', 'chayen,olieang', 'orange,black']\n",
      "INFO:Fixer Logs:Correct CSV format: 2,\"chayen,olieang\",\"orange,black\"\n",
      "INFO:Fixer Logs:['2', 'chayen,olieang,orange', 'black']\n",
      "INFO:Fixer Logs:Correct CSV format: 2,\"chayen,olieang,orange\",black\n"
     ]
    }
   ],
   "source": [
    "! cat logs/comma_fixer_20250918_162429.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what is printed out when `log_file` is set to False, the log file will display any errors that occur for each row, as well as the possible parses if the option is enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using itertools\n",
    "\n",
    "Instead of using the `create_chunk` function, users can also use the `itertools` library to slice the input. It is important that the initial type of the input MUST be a stream or buffer, such as `TextIOBuffer` or `StringIO`, which as an internal `readline` function.\n",
    "\n",
    "An example using `example_3.csv`, which from previous examples, has 8 rows in total.\n",
    "\n",
    "Here, we can specify to only slice the first 5 rows of the file and attempt to parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,username,number_of_platforms,platforms,number_of_cats,cat_names\n",
      "\n",
      "1,john_appleseed,2,facebook,instagram,1,Apple\n",
      "\n",
      "2,john_wick,0,,0,\n",
      "\n",
      "3,bob,1,instagram,2,fluffy,fluffy sr.\n",
      "\n",
      "4,jlaw,1,instagram,1,,snowy\n",
      "\n",
      "File has been processed!\n",
      "Number of total entries: 4            \n",
      " Number of invalid entries: 0\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "file_3_slice = open(\"./examples/example_3.csv\")\n",
    "slice_5 = islice(file_3_slice, 5)\n",
    "\n",
    "# For demonstration on how it looks like\n",
    "for line in slice_5:\n",
    "    print(line)\n",
    "\n",
    "file_3_slice = open(\"./examples/example_3.csv\")\n",
    "parsed_3_first_5 = fixer_3.fix_file(islice(file_3_slice, 10), skip_first_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `itertools.islice`, we can specify exactly which lines to process, and allows more customisability compared to the `create_chunks` function. \n",
    "\n",
    "For example, with `itertools.islice`, a start and stop index can be specified so that only lines from the `start` to `stop` are sliced.\n",
    "\n",
    "For example, using `example_3.csv` again, we can slice lines 3-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,bob,1,instagram,2,fluffy,fluffy sr.\n",
      "\n",
      "4,jlaw,1,instagram,1,,snowy\n",
      "\n",
      "5,tay_fast,2,,instagram,,youtube,3,grey,,benson,button\n",
      "\n",
      "File has been processed!\n",
      "Number of total entries: 3            \n",
      " Number of invalid entries: 0\n"
     ]
    }
   ],
   "source": [
    "file_3_slice = open(\"./examples/example_3.csv\")\n",
    "slice_3to6 = islice(file_3_slice, 3, 6)\n",
    "\n",
    "# For demonstration on how it looks like\n",
    "for line in slice_3to6:\n",
    "    print(line)\n",
    "    \n",
    "file_3_slice = open(\"./examples/example_3.csv\")\n",
    "parsed_3_first_3to6 = fixer_3.fix_file(islice(file_3_slice, 3, 6), skip_first_line=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comma-fixer-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
